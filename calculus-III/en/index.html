<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>Calculus III</title>
        <meta name="description" content="Calculus III: topology of R^n, multi-variable functions, limits, derivatives and extrema of multi-variable functions.">
        <meta name="keywords" content="Calculus III,topology of R^n,multi-variable functions,limits,derivatives,extrema of multi-variable functions">
        <meta name="author" content="George Makris">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src="/mathjax.js"></script>
        <link rel="stylesheet" href="/style.css">
    </head>
    <body id="body">
        <header>
            <div id="title">
                <h1>Calculus III</h1>
            </div>
            <hr>
            <div id="settings">
                <div id="settings_box1">
                    <h3>Language/Γλώσσα:</h3>
                    <p id="language">English/Αγγλικά</p>
                    <p>Για Ελληνικά κλικ <a href="/calculus-III/gr/index.html">εδώ</a></p>
                </div>
                <div id="settings_box2">
                    <h3 id="modes">Change modes:</h3>
                    <div>
                        <button id="defaultMode">default mode</button>
                        <button id="lightMode">classic</button>
                    </div>
                    <div>
                        <button id="darkMode">dark mode</button>
                        <button id="darkMode2">space mode</button>
                    </div>
                    <script src="/colors.js"></script>
                </div>
            </div>
            <hr>
            <h1>Navigation</h1>
            <nav>
                <a href="#part1">Topology of \(\mathbb{R}^n\)</a> |
                <a href="#part2">multi-variable functions</a> |
                <a href="#part3">limits of multi-variable functions</a> |
                <a href="#part4">continuity</a> |
                <a href="#part5">derivatives of multi-variable functions</a> |
                <a href="#part6">gradient and chain rule</a> |
                <a href="#part7">directional derivatives</a> |
                <a href="#part8">extrema of multi-variable functions</a>
            </nav>
            <p>To see the library click <a href="/library/en/index.html">here</a></p>
            <p>If you are using a phone, we suggest rotating it horizontally.</p>
            <p>If at some point you see Mathjax commands instead of math symbols (for example \cup instead of U), try reloading the page. If the issue persists, check <a href="/help/en/index.html">here</a></p>
            <p id="r">Sentences starting with an exclamation mark can be scrolled horizontally if they don't fit on the screen. For more details, visit the library page.</p>
            <hr>
        </header>
        <main>
            <h1 id="part1">Topology of \(\mathbb{R}^n\)</h1>
            <p>We will look at some definitions related to various sets, and once we finish with these, we will move on to functions of multiple variables. The definitions we will examine are general and apply regardless of the number of dimensions we are talking about, which is why we will write \(\mathbb{R}^n\) every time, representing \(n\) dimensions.</p>
            <p>We will denote a point in \(\mathbb{R}^n\) with coordinates \((x_1,x_2,...,x_n)\) as \(\vec{x_0} \in \mathbb{R}^n\). If we are in \(\mathbb{R}^2\), the coordinates will be \((x_1,y_1)\), while in \(\mathbb{R}^3\), they will be \((x_1,y_1,z_1)\).</p>
            <ul>
                <li>For \(n=1\), we have one dimension (1D), the line \(\mathbb{R}\) of real numbers.</li>
                <li>For \(n=2\), we have two dimensions (2D), the plane \(\mathbb{R}^2\) (the plane we worked with in functions of a single variable).</li>
                <li>For \(n=3\), we have three dimensions (3D), the space \(\mathbb{R}^3\) (this is the one we are actually in).</li>
                <li>For \(n \gt 3\), we cannot describe what \(\mathbb{R}^n\) looks like in the same way as before.</li>
            </ul>
            <p>The first thing we will look at is distance.</p>
            <p>Any function \(d:\mathbb{R}^n \to \mathbb{R}\) that satisfies the following properties is called a distance: Let \(\vec{x},\vec{y} \in \mathbb{R}^n\) be points.</p>
            <ul>
                <li>1) \(d(\vec{x},\vec{y}) \ge 0\)</li>
                <li>2) \(d(\vec{x},\vec{y}) = 0 \Leftrightarrow \vec{x} = \vec{y}\)</li>
                <li>3) \(d(\vec{x},\vec{y}) = d(\vec{y},\vec{x})\)</li>
                <li>4) \(d(\vec{x},\vec{y}) \le\) \(d(\vec{x},\vec{z}) + d(\vec{y},\vec{z})\)</li>
            </ul>
            <h4>Distance Measurement:</h4>
            <p>Move right/left by touching the next line if it’s not fully visible (for mobile devices).</p>
            <p class="math-container">\(d(\vec{x},\vec{y}) = \sqrt{(y_1 - x_1)^2 + (y_2 - x_2)^2 + \dots + (y_n - x_n)^2}\)</p>
            <hr>
            <p><h4>Open Spherical Region:</h4> Let point \(\vec{x_0} \in \mathbb{R}^n\) and \(\epsilon > 0\). The open spherical region \(S(\vec{x_0}, \epsilon)\) is all points in \(\mathbb{R}^n\) that are at a distance from \(\vec{x_0}\) smaller than \(\epsilon\).</p>
            <h4>That is, \(S(\vec{x_0}, \epsilon) =\) \(\{\vec{x} \in \mathbb{R}^n : d(\vec{x}, \vec{x_0}) \lt \epsilon\}\)</h4>
            <ul>
                <li>In \(\mathbb{R}\): \(S(\vec{x_0}, \epsilon)\) is the open interval \((- \epsilon, \epsilon)\).</li>
                <li>In \(\mathbb{R}^2\): \(S(\vec{x_0}, \epsilon)\) is the interior of the circle \((x - x_1)^2 + (y - y_1)^2 =\) \(\epsilon^2\). That is, the area inside the circle without its perimeter.</li>
                <li>In \(\mathbb{R}^3\): \(S(\vec{x_0}, \epsilon)\) is the interior of the sphere \((x - x_1)^2 + (y - y_1)^2 +\) \((z - z_1)^2 = \epsilon^2\). That is, the space inside the sphere without its surface.</li>
            </ul>
            <p><h4>Closed Spherical Region:</h4> \(S[\vec{x_0}, \epsilon] =\) \(\{\vec{x} \in \mathbb{R}^n : d(\vec{x}, \vec{x_0}) \le \epsilon\}\)</p>
            <p>That is, the closed spherical region is like the open one, but instead of "less than" in the inequality, we use "less than or equal to".</p>
            <ul>
                <li>In \(\mathbb{R}\): \(S[\vec{x_0}, \epsilon]\) is the closed interval \([-\epsilon, \epsilon]\).</li>
                <li>In \(\mathbb{R}^2\): \(S[\vec{x_0}, \epsilon]\) is the circle \((x - x_1)^2 + (y - y_1)^2 =\) \(\epsilon^2\) and its interior. That is, the interior together with its perimeter.</li>
                <li>In \(\mathbb{R}^3\): \(S[\vec{x_0}, \epsilon]\) is the sphere \((x - x_1)^2 + (y - y_1)^2 +\) \((z - z_1)^2 = \epsilon^2\), together with its interior.</li>
            </ul>
            <p>The spherical regions will be useful for the definitions of almost all the following sets.</p>
            <p><h4>Open Set:</h4> Let \(U \subseteq \mathbb{R}^n\). The set \(U\) is said to be open if \(i)\) \(U = \emptyset\) or \(ii)\) \(U \neq \emptyset\) and for every \(\vec{x} \in U\), there exists \(S(\vec{x_0}, \epsilon)\) such that \(S(\vec{x}, \epsilon) \subseteq U\).</p>
            <p>This definition means that a set is open if for every point in it, there exists an open spherical region (of any size) such that every point in that region also lies within the open set.</p>
            <p><h4>Closed Set:</h4> A set is said to be closed if its complement is open. (The complement of a set \(A\) is \(\mathbb{R}^n \setminus A\)).</p>
            <p><h4>Accumulation Points:</h4> Let \(U \subseteq \mathbb{R}^n\) and \(\vec{x_0} \in \mathbb{R}^n\). The point \(\vec{x_0}\) is said to be an accumulation point of \(U\) if for every \(S(\vec{x_0}, \epsilon)\), it holds that \(S(\vec{x_0}, \epsilon) \cap (U \setminus \{\vec{x_0}\}) \neq \emptyset\).</p>
            <p>In other words, for a point \(\vec{x_0}\) to be an accumulation point of the set \(U\), every open spherical region \(S(\vec{x_0}, \epsilon)\) must have at least one common point with the set \((U \setminus \{\vec{x_0}\})\), which is the set \(U\) without \(\vec{x_0}\).</p>
            <p>The point \(\vec{x_0}\) does not need to belong to \(U\) to be an accumulation point, but it should be "relatively close". For example, in the set \(\{(x, y): x^2 + y^2 \lt 1\}\), which is the set of all points inside the circle centered at (0, 0) with radius 1, the accumulation points are all the points in the set and also all the points on the perimeter of the circle.</p>
            <p>Also, it is not necessarily true that a point is an accumulation point of the set \(U\) just because it belongs to it. For example, in a set consisting of isolated points, none of them is an accumulation point because of \((U \setminus \{\vec{x_0}\})\). Since the point is not included, there is certainly an open spherical region (as small as needed) such that it has no common points with \((U \setminus \{\vec{x_0}\})\).</p>
            <p><h4>Contact Points:</h4> Let \(U \subseteq \mathbb{R}^n\) and \(\vec{x_0} \in \mathbb{R}^n\). The point \(\vec{x_0}\) is said to be a contact point of \(U\) if for every \(S(\vec{x_0}, \epsilon)\), it holds that \(S(\vec{x_0}, \epsilon) \cap U \neq \emptyset\).</p>
            <p>In other words, for a point \(\vec{x_0}\) to be a contact point of the set \(U\), every open spherical region \(S(\vec{x_0}, \epsilon)\) must have at least one common point with the set \(U\).</p>
            <p>Essentially, the contact points of a set are all the points in it and all the accumulation points of it. So, the accumulation points are also contact points, but the reverse is not always true.</p>
            <p><h4>Closure of a Set \(A\):</h4> It is the set of all the contact points of \(A\). It is denoted by \(Cl(A)\). <b id="r">***</b></p>
            <p><h4>Boundary Point:</h4> A point \(\vec{x_0} \in \mathbb{R}^n\) is called a boundary point of a set \(U\) if for every \(S(\vec{x_0}, \epsilon)\), it holds that \(S(\vec{x_0}, \epsilon) \cap U \neq \emptyset\) and \(S(\vec{x_0}, \epsilon) \cap (\mathbb{R}^n \setminus U) \neq \emptyset\).</p>
            <p>That is, a point is a boundary point of \(U\) if "right next to" it, there are points from both \(U\) and points that do not belong to \(U\).</p>
            <p><h4>Boundary of a Set \(A\):</h4> It is the set of all the boundary points of \(A\). It is denoted by \(\partial (A)\), and it holds that \(\partial (A) = Cl(A) \cap Cl(\mathbb{R}^n \setminus A)\).</p>
            <p><h4>Interior Points of a Set \(A\):</h4> These are the points \(x_0\) for which \(\exists\) \(S(\vec{x_0}, \epsilon) \subseteq A\). There must be at least one open spherical region (no matter how small) that is entirely within the set (every point of it belongs to the set).</p>
            <p>The set of all interior points of a set \(A\) is called the interior of \(A\) and is denoted by \(int(A)\).</p>
            <p><b id="r">***</b> It holds that \(Cl(A) = int(A) \cup \partial A\).</p>
            <p><h4>Isolated Point of a Set \(A\):</h4> A point \(\vec{x_0}\) is called an isolated point of \(A\) if \(\exists\) \(S(\vec{x_0}, \epsilon)\) such that \(S(\vec{x_0}, \epsilon) \cap A = \{\vec{x_0}\}\). That is, it should not have any other point from \(A\) "right next" to it.</p>
            <p><h4>Bounded Set:</h4> A set is called bounded if \(\exists\) \(M > 0\) such that \(d(\vec{x}, \vec{y}) \le M\) for all \(\vec{x}, \vec{y}\). In other words, a set that does not extend to infinity. In the plane and space, bounded sets do not require an infinite piece of the plane/space to be drawn. For higher dimensions, we cannot describe it similarly.</p>
            <p><h4>Compact Set:</h4> A set is called compact if it is both closed and bounded.</p>
            <p><h4>Complete Set:</h4> A set is called complete if it is closed (the definition requires sequences, but we will not deal with those, so we can use this without it being a formal definition though).</p>
            <p><h4>Convex Set:</h4> A set \(C\) is called convex if for every \(\vec{x}, \vec{y}\) and for every \(λ \in [0,1]\), it holds that \(λ\vec{x} + (1-λ)\vec{y} \in C\). Practically, for a set to be convex, for any two points in it, the straight line segment they create must also lie within the set. For example, a circle is a convex set, but a set in the shape of a "C" is not, because the straight line segment AB, where A is the start and B is the end of the C, will not lie entirely within the C.</p>
            <p><h4>Connected Set:</h4> A set \(U\) is called connected if there do not exist non-empty open sets \(A\) and \(B\) such that \(A \cup B = U\) and \(A \cap B = \emptyset\). Practically, a connected set is any set that is "joined together." You should be able to start from any point in the set and go to any other point without having to leave the set.</p>
            <p><h4>Important:</h4> Every convex set is connected. The reverse is not true.</p>
            <p>For example, the set \(A \cap B\), where \(A =\) \(\{(x,y) / (x+1)^2 + y^2 \le 1\}\) and \(B =\) \(\{(x,y) / (x-1)^2 + y^2 \le 1\}\), is connected (essentially, it is the union of two circles, one with center \((-1,0)\) and radius 1, and the other with center \((1,0)\) and radius 1, together with their interiors, which touch at exactly one point, \((0,0)\), so the set is connected). However, it is not convex (any straight line segment between a point in \(A\) and a point in \(B\), except those along the \(x\)-axis, will not lie entirely within the set).</p>
            <hr>
            <h1 id="part2">Multi-variable functions</h1>
            <!--space for ad-->
            <p>We will examine functions of the form \(f:\mathbb{R}^n \to \mathbb{R}\) (instead of the entire \(\mathbb{R}^n\), the domain may also be a subset of it). For \(n=1\), we have already studied functions in the course <a href="/functions/en/index.html">"Functions"</a>, so by multi-variable functions, we mean those for \(n \gt 1\).</p>
            <p>To graph a function, \(n+1\) axes are required.</p>
            <ul>
                <li>A \(f:\mathbb{R} \to \mathbb{R}\) takes values from \(\mathbb{R}\) (its domain is the entire x-axis) and produces values in \(\mathbb{R}\). Thus, 1+1=2 axes are needed, and \(f\) produces points in the plane \(\mathbb{R}^2\).</li>
                <li>A \(f:\mathbb{R}^2 \to \mathbb{R}\) takes values from \(\mathbb{R}^2\) (its domain is the entire plane \(\mathbb{R}^2\)) and produces values in \(\mathbb{R}\). Thus, 2+1=3 axes are needed, and \(f\) produces points in space \(\mathbb{R}^3\).</li>
                <li>A \(f:\mathbb{R}^3 \to \mathbb{R}\) takes values from \(\mathbb{R}^3\) (its domain is the entire space \(\mathbb{R}^3\)) and produces values in \(\mathbb{R}\). Thus, 3+1=4 axes are needed, but since there are only 3 spatial dimensions in reality, such functions cannot be graphically represented. Generally, functions with \(n \gt 2\) cannot be visualized.</li>
            </ul>
            <p>However, this does not mean that discussing functions \(f:\mathbb{R}^n \to \mathbb{R}\) for \(n \gt 2\) (more than 2 variables) is meaningless. Many problems require functions with several variables, and although we cannot graph them, we can study them just as we do functions of one variable. Everything we've studied for functions of one variable also applies to functions with several variables, with the only difference being that instead of \(x\), we now have \(\vec{x}=(x_1,x_2,...,x_n)\). Specifically:</p>
            <p>Operations and composition, determining when a function is one-to-one, onto, bounded, when two functions are equal, or when a point is an extremum (either local or global) are all the same as for functions of one variable, except now with \(\vec{x}=(x_1,x_2,...,x_n)\). Therefore, we won't rewrite them here.</p>
            <p>The aspects that change and require explanation are: limits, continuity, derivatives, finding extrema, and integrals. Everything except integrals will be explained in this lesson, in the order mentioned. Integrals will be covered in the next course (<a href="/calculus-IV/en/index.html">"Calculus IV"</a>).</p>
            <hr>
            <h1 id="part3">Limits of Multi-Variable Functions</h1>
            <p>It is recommended to first review the lesson <a href="/limits/en/index.html">"Limits"</a> (for single-variable functions) before proceeding with what we are about to discuss.</p>
            <p><h4>Definition:</h4> Let \(f:A \subseteq \mathbb{R}^n \to \mathbb{R}\) and \(l \in \mathbb{R}\) which is an accumulation point of \(A\). Then, \(\lim_{\vec{x} \to \vec{x_0}} (f(\vec{x})) = l\) if for every \(\epsilon \gt 0\), there exists \(\delta \gt 0\) such that for every \(\vec{x} \in A\), it holds that \(0 \lt d(\vec{x},\vec{x_0}) \lt \delta\) \(\Rightarrow |f(\vec{x})-l| \lt \epsilon\).</p>
            <p>As with single-variable functions, we will describe the process of finding limits geometrically (only for 2-variable functions, we can't with more), in simple terms.</p>
            <p>We consider a function \(f:\mathbb{R}^2 \to \mathbb{R}\), whose graph is represented in the space \(\mathbb{R}^3\). For every point \((x,y)\) in its domain, there corresponds a point \((x,y,z)\) in space. Connecting all such points forms a surface. For simplicity, let’s assume the function is continuous everywhere.</p>
            <p>Now, if we imagine that the plane (the domain) lies on the ground, then the surface (the graph of \(f\)) would resemble a terrain with hills and valleys (due to its monotonicity). That is, it will have slopes going up and down (depending on the function, of course, but imagine it however you prefer). On this surface, we can move in any direction we wish (straight, diagonally, climbing a hill, descending, etc.).</p>
            <p>As we have seen, the limit of a function at a point is the value we approach as we move toward it—that is, the value we are heading toward "just before" we reach the point, not the value at the point itself. If we want the limit at a point \((x_0,y_0)\), we start at another point on the surface and move toward that point, either directly above or below it (or precisely at it, depending on whether the surface lies above or below the plane \(\mathbb{R}^2\)).</p>
            <p>The challenge is that there are not just two ways to approach the point now, as in single-variable functions (from the left and the right). Now, there are infinitely many paths we can take to approach the point (along the \(x'x\) or \(y'y\) axes, straight lines, parabolas, other curves, spirals shrinking toward the point, etc.).</p>
            <p>Let’s choose a path. This will be a line, so it will resemble a single-variable function. To find the limit along this path, we move toward the point from the right and left (with respect to the line), and if we get the same value, then the limit along that path is that value. However, for the limit to exist, the value must be the same along every possible path (infinitely many). Thus, it is not feasible to check each path one by one.</p>
            <p><h4>Important:</h4> However, if we show that at least two paths yield different limit values, then the limit definitely does not exist. We will see how this is done and how to find the limit below:</p>
            <h1>How to Find the Limit of a Function of Two Variables</h1>
            <p>We are given the limit \(\displaystyle \lim_{(x,y) \to (a,b)} (f(x,y))\). Initially, when we mentioned different paths, we meant approaching \((a,b)\) in the following ways:</p>
            <ul>
                <li>Vertically: That is, moving along the line \(x=a\). For \(x=a\), we have \(\displaystyle \lim_{(x,y) \to (a,b)} (f(x,y))=\) \(\displaystyle \lim_{y \to b} (f(y))\) (substituting \(x\) with \(a\)).</li>
                <li>Horizontally: That is, moving along the line \(y=b\). For \(y=b\), we have \(\displaystyle \lim_{(x,y) \to (a,b)} (f(x,y))=\) \(\displaystyle \lim_{x \to a} (f(x))\) (substituting \(y\) with \(b\)).</li>
                <li>Diagonally: That is, moving along a line \(y=mx\), where \(m\) is its slope. For \(y=mx\), we have \(\displaystyle \lim_{(x,y) \to (a,b)} (f(x,y))=\) \(\displaystyle \lim_{x \to a} (f(x))\) (substituting \(y\) with \(mx\)). It is important to ensure the chosen line passes through the point, otherwise how would we approach it? For example, the line \(y=x\), which is the most well-known, can only be chosen for points of the form \((a,a)\).</li>
                <li>Others: Moving along parabolas (\(y=x^2, x=y^2, \dots)\), etc. (substituting \(y\) with \(x^2\) for the first case).</li>
            </ul>
            <p>By following these paths, if the limit does not exist, it is quite likely that at least two paths will yield different values, allowing us to conclude that the limit indeed does not exist.</p>
            <p>If the same value is obtained for all paths, this does not necessarily mean the limit exists, but it is possible. For this reason, we use one of the following three methods to find it (or even determine that it does not exist after all):</p>
            <p>1) The definition (not recommended unless explicitly required), 2) the squeeze theorem (works exactly like in single-variable functions), 3) using polar coordinates (recommended).</p>
            <h1>Finding the Limit Using Polar Coordinates</h1>
            <p>You need a bit of analytic geometry. If you’d like to review some concepts, check <a href="analytic_geometry.html">here</a>.</p>
            <ul>
                <li>If \((a,b)\) is not \((0,0)\), we transform the coordinate system so that \((a,b)\) becomes the center \((0,0)\). This is done by setting \(s=x-a\) and \(t=y-b\). Thus, we now work in a coordinate system centered at \((a,b)\) with axes \(s,t\), which is a parallel translation of the original system \(Oxy\).</li>
                <li>Therefore, when \((x,y) \to (a,b)\), we have \((s,t) \to (0,0)\) and \(f(x,y)=f(s+a,t+b)\).</li>
                <li>We set \(s=r \cdot \cos(\theta)\) and \(t=r \cdot \sin(\theta)\), so for \((s,t) \to (0,0)\), it suffices that \(r \to 0\)<b id="r">*</b>.</li>
                <li class="math-container">! Thus, \(f(x,y)=f(a+r \cdot \cos(\theta),b+r \cdot \sin(\theta))\), which implies \(\displaystyle \lim_{(x,y) \to (a,b)} (f(x,y)) = \lim_{(r,\theta) \to (0,0)} (f(a+r \cdot \cos(\theta),b+r \cdot \sin(\theta)))\).</li>
                <li>The reason for this transformation is that \(\theta\) represents the path we take. Therefore, if the limit is independent of the value of \(\theta\), then the limit exists and equals the value we compute. If it depends on \(\theta\), the limit does not exist. Additionally, if the result is infinity (\(+\infty\) or \(-\infty\)), we still conclude that the limit does not exist, but we note that it diverges to infinity.</li>
                <li>If \((a,b)\) was (0,0) we would set right away without transforming the coordinate system.</li>
                <p><b id="r">*</b>Since \(r\) represents a length, it is always positive, so the notion of \(r \to 0^-\) does not apply.</p>
            </ul>
            <hr>
            <h4>Example:</h4>
            <p>For \(\displaystyle \lim_{(x,y) \to (0,0)} \left(\frac{x \cdot y}{x^2+y^2}\right)\), let’s check a few paths: for \(x=0\): \(\displaystyle \lim_{y \to 0} \left(\frac{0}{y^2}\right)=0\). For \(y=0\): \(\displaystyle \lim_{x \to 0} \left(\frac{0}{x^2}\right)=0\). For \(y=x\): \(\displaystyle \lim_{x \to 0} \left(\frac{x^2}{2x^2}\right)=\frac{1}{2}\), so the limit does not exist.</p>
            <p>Now, let’s analyze it using polar coordinates. The point is \((0,0)\), so no coordinate system transformation is needed. We set \(x=r \cdot \cos(\theta)\) and \(y=r \cdot \sin(\theta)\), and thus, for \((x,y) \to (0,0)\), it suffices that \(r \to 0\).</p>
            <p class="math-container">\(! \displaystyle \lim_{(x,y) \to (0,0)} \left(\cfrac{x \cdot y}{x^2+y^2}\right) = \lim_{(r,\theta) \to (0,0)} \left(\cfrac{r^2 \cos(\theta) \sin(\theta)}{r^2 \cos^2(\theta)+r^2 \sin^2(\theta)}\right) = \lim_{(r,\theta) \to (0,0)} \left(\cfrac{r^2 \cos(\theta) \sin(\theta)}{r^2 (\cos^2(\theta)+\sin^2(\theta))}\right) = \lim_{(r,\theta) \to (0,0)} \left(\cfrac{\cos(\theta) \sin(\theta)}{1}\right)\). The limit depends on the value of \(\theta\), so it does not exist.</p>
            <hr>
            <h1>How to Find the Limit of a Function of Three Variables</h1>
            <p>We are given the limit \(\displaystyle \lim_{(x,y,z) \to (a,b,c)} (f(x,y,z))\). We approach \((a,b,c)\) using the following methods:</p>
            <ul>
                <li>Along the x-axis: For \(y=b\) and \(z=c\), we calculate \(\displaystyle \lim_{x \to a} f(x)\).</li>
                <li>Along the y-axis: For \(x=a\) and \(z=c\), we calculate \(\displaystyle \lim_{y \to b} f(y)\).</li>
                <li>Along the z-axis: For \(x=a\) and \(y=b\), we calculate \(\displaystyle \lim_{z \to c} f(z)\).</li>
                <li>Other paths: We test other combinations, such as \(y=x^2\), etc.</li>
            </ul>
            <p>By following these paths, if the limit does not exist, it is likely that at least two paths yield different values, allowing us to conclude that the limit indeed does not exist.</p>
            <p>If the same value is obtained for all paths, it does not necessarily mean that the limit exists, but it becomes more likely. To confirm, we use one of the following three methods (or determine that the limit does not exist after all):</p>
            <p>1) Definition (not recommended unless explicitly required) 2) Squeeze Theorem (works the same way as with single-variable functions) 3) Use of spherical coordinates (recommended)</p>
            <h1>Finding the Limit Using Spherical Coordinates</h1>
            <ul>
                <li>If \((a,b,c)\) is not \((0,0,0)\), we transform the coordinate system so that \((a,b,c)\) becomes the origin \((0,0,0)\). This is done by setting \(s=x-a\), \(t=y-b\), and \(u=z-c\). Thus, we are now in a coordinate system centered at \((a,b,c)\) with axes \(s,t,u\), which is a parallel translation of the original system \(Oxyz\).</li>
                <li>Hence, when \((x,y,z) \to (a,b,c)\), we have \((s,t,u) \to (0,0,0)\) and \(f(x,y,z)=\) \(f(s+a,t+b,u+c)\).</li>
                <li>We set \(s=r \cdot \sin(\phi)\cos(\theta)\), \(t=r \cdot \sin(\phi)\sin(\theta)\), and \(u=r \cdot \cos(\phi)\). Therefore, for \((s,t,u) \to (0,0,0)\), it suffices that \(r \to 0\).</li>
                <li class="math-container">! We have \(f(x,y,z)=f(a+r \cdot \sin(\phi)\cos(\theta), b+r \cdot \sin(\phi)\sin(\theta), c+r \cdot \cos(\phi))\), so \(\displaystyle \lim_{(x,y,z) \to (a,b,c)} (f(x,y,z)) = \lim_{(r,\phi,\theta) \to (0,0,0)} (f(a+r \cdot \sin(\phi)\cos(\theta), b+r \cdot \sin(\phi)\sin(\theta), c+r \cdot \cos(\phi)))\).</li>
                <li>The reason for this transformation is that \(\theta\) and \(\phi\) represent the path we take. Therefore, if the limit is independent of their values, it exists and equals the result we find. If it depends on them, the limit does not exist. Furthermore, if the result is infinity (positive or negative), we also conclude that the limit does not exist, but we note that it diverges to infinity.</li>
                <li>If \((a,b,c)\) was (0,0,0) we would set right away without transforming the coordinate system.</li>
            </ul>
            <p>We will not see limits of functions with more than 3 variables in this course (and generally on this website).</p>
            <hr>
            <h4>Iterated Limits:</h4>
            <p>If we know for sure that the limit \(\displaystyle \lim_{(x_1,\dots,x_n) \to (c_1,\dots,c_n)} f(\vec{x})\) exists, we can write it as:</p>
            <p class="math-container">\(! \displaystyle \lim_{x_1 \to c_1} ( \lim_{x_2 \to c_2} ( \dots \lim_{x_n \to c_n} (f(\vec{x}))\dots))\).</p>
            <p>The existence of iterated limits does NOT guarantee the existence of the overall limit, which is why this method is almost never used.</p>
            <hr>
            <h1 id="part4">Continuity</h1>
            <!--space for ad-->
            <p>A function \(f:A \subseteq \mathbb{R}^n \to \mathbb{R}\) is continuous at a point \(\vec{x_0}\) if one of the following holds:</p>
            <ul>
                <li>The point \(\vec{x_0}\) is an isolated point of \(A\).</li>
                <li>\(\displaystyle \lim_{x \to \vec{x_0}} f(x) = f(\vec{x_0})\)</li>
            </ul>
            <h4>Properties:</h4>
            <ul>
                <li>A function is continuous if it is continuous at every point in its domain.</li>
                <li>All sequences are continuous.</li>
                <li>All polynomial, rational, logarithmic, exponential, trigonometric, etc. (basic) functions are continuous.</li>
                <li>The operations and composition of continuous functions yield continuous functions.</li>
                <li>If the set \(A\) is compact and \(f\) is continuous, then \(f(A)\) is compact, bounded, and \(f\) attains a maximum and minimum value.</li>
                <li>If the set \(A\) is connected and \(f\) is continuous, then \(f(A)\) is connected.</li>
            </ul>
            <h1>Uniform Continuity</h1>
            <p>A function \(f:A \subseteq \mathbb{R}^n \to \mathbb{R}\) is called uniformly continuous on \(B \subseteq A\) if and only if:</p>
            <p class="math-container">For every \(\epsilon \gt 0\), there exists \(\delta \gt 0\) such that for all \(\vec{x},\vec{y} \in B\), \(d(\vec{x},\vec{y}) \lt \delta \Rightarrow |f(\vec{x})-f(\vec{y})| \lt \epsilon.\)</p>
            <p><h4>Theorem:</h4> If \(f\) is continuous and bounded on a closed set (i.e., continuous on a compact set), then it is uniformly continuous on that set.</p>
            <p>Geometrically, uniform continuity means that the graph of the function does not change abruptly. For example, if the limit of a function at some point is \(\pm \infty\), then the function is automatically not uniformly continuous. It may be uniformly continuous on some subset of its domain but definitely not in general.</p>
            <p>\(f\) uniformly continuous \(\Rightarrow\) \(f\) continuous. The converse (\(\Leftarrow\)) does not hold.</p>
            <hr>
            <h1 id="part5">Partial Derivatives</h1>
            <p>It is recommended to review the lesson <a href="/derivatives/en/index.html">"Derivatives"</a> (for functions of a single variable), as it thoroughly explains the concept of derivatives, how to compute them, and much more, which will not be repeated here.</p>
            <p>Let \(f:A \subseteq \mathbb{R}^3 \to \mathbb{R}\) and \((x_0,y_0,z_0) \in A\). Then:</p>
            <ul>
                <li>\(f\) is said to be partially differentiable with respect to \(x\) at the point \((x_0,y_0,z_0)\) if the following limit exists:</li>
                <li class="math-container">\(\text{ ! } \displaystyle \lim_{h \to 0} \left(\frac{f(x_0+h,y_0,z_0)-f(x_0,y_0,z_0)}{h} \right)\)</li>
                <li>\(f\) is said to be partially differentiable with respect to \(y\) at the point \((x_0,y_0,z_0)\) if the following limit exists:</li>
                <li class="math-container">\(\text{ ! } \displaystyle \lim_{h \to 0} \left(\frac{f(x_0,y_0+h,z_0)-f(x_0,y_0,z_0)}{h} \right)\)</li>
                <li>\(f\) is said to be partially differentiable with respect to \(z\) at the point \((x_0,y_0,z_0)\) if the following limit exists:</li>
                <li class="math-container">\(\text{ ! } \displaystyle \lim_{h \to 0} \left(\frac{f(x_0,y_0,z_0+h)-f(x_0,y_0,z_0)}{h} \right)\)</li>
                <li>The same applies to fewer or more variables, meaning \(+h\) is added to the variable with respect to which the partial derivative is taken.</li>
            </ul>
            <h4>Notations:</h4>
            <ul>
                <li>Partial derivative with respect to \(x\): \(\cfrac{\partial f}{\partial x}\) or \(f_x\)</li>
                <li>Partial derivative with respect to \(y\): \(\cfrac{\partial f}{\partial y}\) or \(f_y\)</li>
                <li>Partial derivative with respect to \(z\): \(\cfrac{\partial f}{\partial z}\) or \(f_z\)</li>
                <li>Similarly for other variables.</li>
                <li>In all cases, we include \((x,y,...)\) afterwards. For example, \(\cfrac{\partial f}{\partial x} (x,y)\), \(g_z(x,y,z)\), etc.</li>
            </ul>
            <p><h4>Definition:</h4> A function \(f\) is called partially differentiable at the point \((x_0,y_0,z_0)\) if it is differentiable with respect to all its variables.</p>
            <p>By finding the above limits for a general point \((x_0,y_0,z_0)\), i.e., without assigning specific numbers to the variables, we obtain (if they exist) the partial derivatives of \(f\), which are functions that give the value of each partial derivative for every point in the domain of \(f\) where it is partially differentiable.</p>
            <p>For example, for the function \(f(x)=x^2+y\), we will compute its partial derivatives generally for a random point \((x_0,y_0)\).</p>
            <p class="math-container">\(\text{ ! } \displaystyle \lim_{h \to 0} \left(\frac{f(x_0+h,y_0)-f(x_0,y_0)}{h} \right) = \lim_{h \to 0} \left(\frac{(x_0+h)^2+y_0-x_0^2-y_0)}{h} \right) = \lim_{h \to 0} \left(\frac{(x_0^2+2x_0h+h^2-x_0^2)}{h} \right) = \lim_{h \to 0} \left(\frac{2x_0h+h^2}{h} \right) = \lim_{h \to 0} (2x_0+h) = 2x_0\), hence \(f_x(x,y)=2x\)</p>
            <p class="math-container">\(\text{ ! } \displaystyle \lim_{h \to 0} \left(\frac{f(x_0,y_0+h)-f(x_0,y_0)}{h} \right) = \lim_{h \to 0} \left(\frac{x_0^2+y_0+h-x_0^2-y_0)}{h} \right) = \lim_{h \to 0} \left(\frac{h}{h} \right) = 1\), hence \(f_y(x,y)=1\) at every point.</p>
            <h1>Finding Partial Derivatives</h1>
            <p>Obviously, we don't need to use the definition every time as shown above. To find a partial derivative, we follow the procedure below.</p>
            <p>The same rules as for derivatives of single-variable functions apply, except we treat all other variables as constants (numbers). All known rules for operations, composition, and derivatives of basic functions hold true.</p>
            <p>For example, for <span class="size">\(f(x,y,z)=e^{yx^2+y+z^3}\)</span>:</p>
            <p class="math-container size">\(\text{ ! } f_x(x,y,z)=e^{yx^2+y+z^3} \cdot (2xy+0+0) = 2xy \cdot e^{x^2+y+z^3}\)</p>
            <p class="math-container size">\(\text{ ! } f_y(x,y,z)=(x^2+1) \cdot e^{yx^2+y+z^3}\)</p>
            <p class="math-container size">\(\text{ ! } f_z(x,y,z)=3z^2 \cdot e^{yx^2+y+z^3}\)</p>
            <h4>Higher-Order Derivatives</h4>
            <p>These are the derivatives of derivatives. Notations:</p>
            <ul>
                <li>2nd partial derivative with respect to \(x\): \(\cfrac{\partial^2 f}{\partial x^2}\) ή \(f_{xx}\)</li>
                <li>2nd partial derivative with respect to \(y\): \(\cfrac{\partial^2 f}{\partial y^2}\) ή \(f_{y y}\)</li>
                <li>Mixed: \(\cfrac{\partial^2 f}{\partial xy}\) ή \(f_{xy}\)</li>
                <li>Mixed: \(\cfrac{\partial^3 f}{\partial x z y}\) ή \(f_{x z y}\)</li>
                <li>Similarly for any combination.</li>
            </ul>
            <p>For mixed derivatives, differentiation is performed in the order they are written, e.g., \(f_{x z y}(x,y,z) =\) \(f_y(f_z(f_x(x,y,z)))\).</p>
            <p><h4>Schwartz Theorem:</h4> For functions with continuous partial derivatives up to the required order, the order of differentiation does not matter (for mixed derivatives).</p>
            <p>Geometrically, we know that the derivative represents the slope of a function (for a single variable). For functions of multiple variables, the partial derivative with respect to a variable represents the slope of the function when moving along the axis of that variable (e.g., the partial derivative with respect to \(x\): slope along the \(x\)-axis).</p>
            <p>The geometric description of finding a derivative by examining the graph provided in the lesson "Derivatives" can also be applied to functions of two variables if we consider that the domain plane lies on the ground and the graph is a surface resembling a plain with mountains. What was explained there also holds here but applies to each axis separately. That is, in single-variable cases, we moved over the entire graph of \(f\) to reach a point, whereas here we move only along a specific part of the graph, specifically the line above/below the axis of interest. You can see the details there.</p>
            <p>To find the derivative when moving along a different line and not the primary axes, we use the directional derivative (or derivative in a given direction), which we will discuss shortly. Geometrically, the process is the same except that instead of the axes, we move along the desired line.</p>
            <hr>
            <h1 id="part6">Gradient</h1>
            <!--space for ad-->
            <p>For a function \(f\) of \(n\) variables \((x_1,x_2,...,x_n)\), its gradient vector or gradient is:</p>
            <p class="math-container">\(\text{ ! } \nabla f(x_1,...,x_n) = (f_{x_1}(x_1,...,x_n),f_{x_2}(x_1,...,x_n),...,f_{x_n}(x_1,...,x_n))\)</p>
            <h4>Properties:</h4>
            <ul>
                <li>\(\nabla (f + g) = \nabla f + \nabla g\)</li>
                <li>\(\nabla (f - g) = \nabla f - \nabla g\)</li>
                <li>\(\nabla (f \cdot g) =\) \((\nabla f) \cdot g + f \cdot (\nabla g)\)</li>
                <li>\(\nabla \left(\cfrac{f}{g}\right) =\cfrac{(\nabla f) \cdot g - f \cdot (\nabla g)}{g^2}\)</li>
                <li>\(\nabla (c \cdot f) = c \cdot \nabla f\)</li>
            </ul>           
            <hr>
            <h1>Chain Rule</h1>
            <p>It is used to differentiate composite functions whose variables can be expressed as functions of another variable.</p>
            <h4>For one variable:</h4>
            <p>Let \(f:A \subseteq \mathbb{R} \to \mathbb{R}\) with formula \(f(x)\) and \(x=x(t)\). Then \(\cfrac{df}{dt} = \cfrac{df}{dx} \cdot \cfrac{dx}{dt}\). Thus, it is not necessary to find the formula \(f(t)\) and differentiate it, although we could if we wanted to. Therefore, one can choose whatever seems easier at the moment.</p>
            <h4>For two variables:</h4>
            <p>Let \(f:A \subseteq \mathbb{R}^2 \to \mathbb{R}\) with formula \(f(x,y)\) and \(x=x(t),y=y(t)\). Then \(\cfrac{df}{dt} = \cfrac{\partial f}{\partial x} \cdot \cfrac{dx}{dt} + \cfrac{\partial f}{\partial y} \cdot \cfrac{dy}{dt}\). Again, we could find the formula \(f(t)\) and differentiate it if we wanted to.</p>
            <p>Let \(f:A \subseteq \mathbb{R}^2 \to \mathbb{R}\) with formula \(f(x,y)\) and \(x=x(s,t),y=y(s,t)\). Then \(\cfrac{\partial f}{\partial t} = \cfrac{\partial f}{\partial x} \cdot \cfrac{\partial x}{\partial t} + \cfrac{\partial f}{\partial y} \cdot \cfrac{\partial y}{\partial t}\) and \(\cfrac{\partial f}{\partial s} = \cfrac{\partial f}{\partial x} \cdot \cfrac{\partial x}{\partial s} + \cfrac{\partial f}{\partial y} \cdot \cfrac{\partial y}{\partial s}\). We could find the formula \(f(s,t)\) and compute any partial derivative from it.</p>
            <p>The same applies for more variables.</p>
            <p>We will not show an example since the process is exactly as described. You identify which case the function belongs to and substitute into the formula.</p>
            <hr>
            <h1 id="part7">Directional Derivative</h1>
            <p>As mentioned earlier, it is similar to partial derivatives, but instead of measuring the slope along the axes, it measures the slope in the direction of a vector \(\vec{v}\) (which must be normalized, i.e., with \(||\vec{v}||=1\)). If the vector we want is not normalized, we use the vector \(\vec{v'}=\cfrac{\vec{v}}{||\vec{v}||}\).</p>
            <p>The directional derivative of \(f:A \subseteq \mathbb{R}^n \to \mathbb{R}\) at the point \(\vec{x_0}=(x_1,...,x_n)\), in the direction of the vector \(\vec{v}=(v_1,...,v_n)\) (with \(||\vec{v}||=1\)) is:</p>
            <p class="math-container">\(\text{ ! } \displaystyle D_v f(\vec{x_0}) = \lim_{h \to 0} \left( \frac{f(\vec{x_0}+h \cdot \vec{v})-f(\vec{x_0})}{h} \right) = \lim_{h \to 0} \left( \frac{f(x_1+h \cdot v_1,x_2+h \cdot v_2,...,x_n+h \cdot v_n,)-f(x_1,x_2,...,x_n)}{h} \right)\)</p>
            <p><h4>Important: </h4> \(D_v f(\vec{x_0}) = \nabla f(\vec{x_0}) \cdot \vec{v}\)</p>
            <hr>
            <h1 id="part8">Extrema of Multi-variable Functions</h1>
            <!--space for ad-->
            <p>The definitions are the same as those for functions of one variable, except here we have \(\vec{x_0}\) instead of just \(x\). The possible locations of extrema for a function are:</p>
            <ul>
                <li>The interior points of its domain where \(\nabla f(\vec{x})=\vec{0}.\)</li>
                <li>The interior points of its domain where \(\nabla f\) is not defined.</li>
                <li>The boundary points of its domain.</li>
            </ul>
            <p>The critical points of a function are the interior points of its domain where \(\nabla f\) is zero or undefined.</p>
            <p>Saddle points are the points where the concavity of the function changes (we encountered them as inflection points in high school).</p>
            <h1>How to Find Extrema of Multi-variable Functions</h1>
            <p>There are 3 cases: 1) The domain consists only of a boundary. 2) The domain has no boundary. 3) The domain includes both a boundary and points not on the boundary.</p>
            <h1>Lagrange Method</h1>
            <p>If the domain of the function is only a boundary (i.e., the boundary of \(A\) is the same as \(A\)), we apply the Lagrange method. In this case, the domain is defined by an equality relation (e.g., \(f:A \subseteq \mathbb{R}^2 \to \mathbb{R}\), where \(A=\{(x,y) / x^2 + y^2 = 1\}\), and we rewrite it in the form \(g(\vec{x})=0\) (in our example: \(x^2+y^2=1\), so \(x^2+y^2-1=0\), hence \(g(\vec{x})=x^2+y^2-1\)).</p>
            <p>The relation must strictly be \(=\). If there is also an inequality (e.g., \(\le\)), it belongs to the third case we will discuss later. If you understand how \(g\) is derived, we can now look at the steps of this method:</p>
            <ul>
                <li>Find the function \(g\) derived from the equality relation in the domain.</li>
                <li>Solve the system \(\begin{cases} \nabla f(\vec{x}) = \lambda \cdot \nabla g(\vec{x}) \\ g(\vec{x})=0 \end{cases}\), where \(\lambda \in \mathbb{R}\). The system is \((n+1) \times (n+1)\), where \(n\) is the number of variables in \(f\), and the \(+1\) is because we also solve for \(\lambda\).</li>
                <li>The solutions correspond to <u>all</u> extrema of \(f\). By substituting the points into the formula, the values of the extrema are obtained.</li>
                <li>The largest value corresponds to the global maximum, while the smallest to the global minimum. Intermediate values correspond to local extrema. If we care about distinguishing between local maxima and minima, we can use the Hessian matrix, which we will cover in the next method.</li>
            </ul>
            <h4>Remarks:</h4>
            <p>\(1)\) If there are multiple relations in the domain, all of them must be used. That is, if we have \(g_1(\vec{x})=0, g_2(\vec{x})=0,...,\) \(g_k(\vec{x})=0\), we will have \(λ_1, λ_2,..., λ_k\) instead of just one \(λ\), and the system becomes \((n+k) \times (n+k)\) as follows:</p>
            <p class="math-container">\(\text{ ! } \begin{cases} \nabla f(\vec{x}) = \lambda_1 \cdot \nabla g_1(\vec{x}) + \lambda_2 \cdot \nabla g_2(\vec{x}) + ... + \lambda_k \cdot \nabla g_k(\vec{x}) \\ g_1(\vec{x})=0 \\ \vdots \\ g_k(\vec{x})=0 \end{cases}\)</p>
            <p>\(2)\) Instead of directly using \(\nabla f(\vec{x}) = \lambda \cdot \nabla g(\vec{x})\), you may also see the Lagrange function defined as \(L(\vec{x}) = \nabla f(\vec{x}) - \lambda \cdot \nabla g(\vec{x})\), and the system as \(\nabla L(\vec{x}) = \vec{0}\). This approach is equivalent to what we did, just presented more explicitly.</p>
            <p>\(3)\) We remind you that for the Lagrange method, the existence of an equality relation in the domain is necessary, and the boundary of the set must coincide with the set itself.</p>
            <p>\(4)\) The Lagrange method guarantees the discovery of all extrema.</p>
            <h1>Hessian Method</h1>
            <p>This method is applied when the domain of \(f\) has no boundary. Steps:</p>
            <ul>
                <li>Find the partial derivatives of \(f\), \(f_{x_1}, f_{x_2}, \ldots, f_{x_n}\).</li>
                <li>Solve the system \(\nabla f(\vec{x}) = \vec{0}\) to find the possible locations of extrema of \(f\).</li>
                <li>Compute the second and mixed derivatives (the Schwartz theorem mentioned earlier is important here) and construct the Hessian matrix:</li>
                <li class="math-container">
                    \(
                    \text{ ! } H(\vec{x}) =
                    \begin{pmatrix}
                    f_{x_1 x_1}(\vec{x}) & f_{x_1 x_2}(\vec{x}) & \ldots & f_{x_1 x_n}(\vec{x}) \\
                    f_{x_2 x_1}(\vec{x}) & f_{x_2 x_2}(\vec{x}) & \ldots & f_{x_2 x_n}(\vec{x}) \\
                    \vdots & \vdots & \ddots & \vdots \\
                    f_{x_n x_1}(\vec{x}) & f_{x_n x_2}(\vec{x}) & \ldots & f_{x_n x_n}(\vec{x})
                    \end{pmatrix}
                    \)
                </li>
                <li>If this seems complex, just think of the entries of a simple matrix \(A\), e.g., \(i\)-th row and \(j\)-th column: element \(a_{i j}\). The same applies here but with derivatives. In position \((i,j)\), the derivative is <b class="size">\(f_{x_i x_j}\).</b></li>
                <li>For each point, check the following by substituting the point \(\vec{x_0}\) into \(H(\vec{x})\):</li>
                <ol>
                    <li>If all principal minors starting from the top-left are positive, then at \(\vec{x_0}\) there is a local minimum.</li>
                    <li>If all principal minors starting from the top-left alternate in sign (first negative, then positive, negative, ...), then at \(\vec{x_0}\) there is a local maximum.</li>
                    <li>If all principal minors starting from the top-left are \(\neq 0\), but neither \(1)\) nor \(2)\) holds, then there is no extremum at \(\vec{x_0}\). The \(\vec{x_0}\) though, is a saddle point.</li>
                    <li>If any principal minor is \(0\), then no conclusion can be drawn for the point \(\vec{x_0}\).</li>
                </ol>
            </ul>
            <h4>Remarks:</h4>
            <p>\(1)\) If \(\nabla f\) is defined at every interior point of the domain (all points are interior since we are using this method), then this method checks all possible extrema points. If no principal minor is \(0\) during the checks, all extrema will have been found.</p>
            <p>\(2)\) An example of this method will be provided at the end, just like for the other methods.</p>
            <h1>Combination</h1>
            <p>The third case is when a function has a domain with a boundary, but this boundary is not the entire set (there are points that belong to the domain but not to its boundary).</p>
            <p>Here, as the title suggests, we use both methods. The first one gives us the extrema on the boundary, while the second one provides the rest that do not belong to the boundary.</p>
            <hr>
            <h4>Example</h4>
            <p>We will see an example of the third case to examine both methods together. Let \(f:A \subseteq \mathbb{R}^2 \to \mathbb{R}\) with the formula \(f(x,y)=x^2-y^2\), where \(A=\) \(\{(x,y) \in \mathbb{R}^2 / x^2+y^2 \le 4\}\). The domain of \(f\) has the boundary defined by the circle \(x^2+y^2 = 4\), so we will use the Lagrange method to find the extrema on the boundary (if they exist), and the Hessian method for the extrema inside the circle, i.e., for points satisfying \(x^2+y^2 \lt 4\).</p>
            <p>We will need both methods, so we write the derivatives here at the beginning: \(f_x(x,y) = 2x\) and \(f_y(x,y) = -2y\), and \(f_{xy}(x,y) = f_{yx}(x,y) = 0\)</p>
            <p>Also, \(\nabla f(x,y) = (2x, -2y)\)</p>
            <h4>Lagrange Method:</h4>
            <p>We have \(x^2+y^2 = 4 \Leftrightarrow\) \(x^2+y^2-4=0\), so \(g(x,y)=x^2+y^2-4\). We calculate: \(g_x(x,y)=2x\) and \(g_y(x,y)=2y\), so \(\nabla g(x,y)=(2x,2y)\)</p>
            <p class="math-container">! Solving \(\begin{cases} \nabla f(x,y)=λ \cdot \nabla g(x,y) \\ g(x,y)=0 \end{cases} \Leftrightarrow \begin{cases} (2x, -2y)=(2λx, 2λy) \\ x^2+y^2=4 \end{cases} \Leftrightarrow \begin{cases} 2x = 2λx \\ -2y = 2λy \\ x^2+y^2=4 \end{cases}\)</p>
            <p>Let's look at the first equation. For \(x \neq 0\), we have \(λ=1\), and substituting this into the second equation gives \(2y=-2y\), so \(y=0\). For \(y=0\) and \(x \neq 0\), the third equation gives \(x=2\) or \(x=-2\). Therefore, so far, we have the points \((-2,0)\) and \((2,0)\).</p>
            <p>Now, we look at the second equation. For \(y \neq 0\), we have \(λ=-1\), and substituting this into the first equation gives \(x=0\). For \(x=0\) and \(y \neq 0\), the third equation gives \(y=2\) or \(y=-2\). Therefore, we obtain the points \((0,-2)\) and \((0,2)\).</p>
            <p>We have essentially checked the system for every \(x,y \in A\) because we considered both \(x \neq 0\) and \(x=0\), and similarly for \(y\). Therefore, we have found all the extrema that lie on the boundary.</p>
            <h4>Hessian Method:</h4>
            <p>Now, for the interior of the circle, we solve the system \(\nabla f(x,y) = \vec{0}\) to find the possible positions of extrema. This gives \((2x,-2y)=(0,0) \Leftrightarrow\) \(2x=0 \text{ and } -2y=0 \Leftrightarrow\) \(x=0 \text{ and } y=0\), so the only point is \((0,0)\).</p>
            <p class="math-container">! \( H(x,y)=\begin{pmatrix} 2 & 0 \\ 0 & -2 \end{pmatrix}\), since \(f_{xx}(x,y)=2\), \(f_{yy}(x,y)=-2\), and \(f_{xy}(x,y) = f_{yx}(x,y) = 0\)</p>
            <p>Now, we look at all the leading principal minors starting from the top left. For the point \((0,0)\): \(det(2)=2 \gt 0\) and \(det(H(0,0))=-4 \cdot 0 - 0 =\) \(-4 \lt 0\). The conditions for neither a maximum nor a minimum are satisfied, and since no minor is \(0\), the point \((0,0)\) is a saddle point.</p>
            <p>Finally, we find the values of the extrema. So, \(f(2,0)=f(-2,0)=4\), \(f(0,2)=f(0,-2)=-4\). Therefore, the function \(f\) has a global maximum of 4 and a global minimum of -4, globally because we have found all the extrema, so there cannot be any other points.</p>
            <hr>     
        </main>
        <footer>
            <div id="end"><a href="#body">go back</a></div>
            <div id="end"><a href="/index.html">homepage</a></div>
            <div id="end"><a href="/calculus-IV/en/part1.html">next course</a></div>
            <hr>
            <div id="ending">&copy; freemath. All rights reserved.</div>
        </footer>
    </body>
</html>